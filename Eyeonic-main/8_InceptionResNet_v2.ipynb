{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "036928b8",
   "metadata": {},
   "source": [
    "# Required Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feebf462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "class Plotter:\n",
    "    def __init__(self, class_names):\n",
    "        self.class_names = class_names\n",
    "\n",
    "    def plot_metrics(self, history, test_run, index):\n",
    "        metrics2 = ['loss', 'auc', 'precision', 'recall']\n",
    "        for n, metric in enumerate(metrics2):\n",
    "            name = metric.replace(\"_\", \" \").capitalize()\n",
    "            plt.subplot(2, 2, n + 1)\n",
    "            plt.plot(history.epoch, history.history[metric], color='green', label='Train')\n",
    "            plt.plot(history.epoch, history.history['val_' + metric], color='green', linestyle=\"--\", label='Val')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel(name)\n",
    "            if metric == 'loss':\n",
    "                plt.ylim([0, plt.ylim()[1]])\n",
    "            elif metric == 'auc':\n",
    "                plt.ylim([0, 1])\n",
    "            else:\n",
    "                plt.ylim([0, 1])\n",
    "\n",
    "            plt.legend()\n",
    "\n",
    "        #fig_manager = plt.get_current_fig_manager()\n",
    "        #fig_manager.full_screen_toggle()\n",
    "        plt.subplots_adjust(top=0.97, bottom=0.09, left=0.10, right=0.96, hspace=0.25, wspace=0.26)\n",
    "        plt.savefig(test_run)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    def plot_input_images(self, x_train, y_train):\n",
    "        plt.figure(figsize=(9, 9))\n",
    "        for i in range(100):\n",
    "            plt.subplot(10, 10, i + 1)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.grid(False)\n",
    "            plt.imshow(x_train[i])\n",
    "            classes = \"\"\n",
    "            for j in range(8):\n",
    "                if y_train[i][j] >= 0.5:\n",
    "                    classes = classes + self.class_names[j] + \"\\n\"\n",
    "            plt.xlabel(classes, fontsize=7, color='black', labelpad=1)\n",
    "\n",
    "        plt.subplots_adjust(bottom=0.04, right=0.95, top=0.94, left=0.06, wspace=0.56, hspace=0.17)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_image(self, i, predictions_array, true_label, img):\n",
    "        predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
    "        plt.grid(False)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "\n",
    "        plt.imshow(img)\n",
    "        label_check = [0,0,0,0,0,0,0,0]\n",
    "        ground = \"\"\n",
    "        count_true = 0\n",
    "        predicted_true = 0\n",
    "\n",
    "        for index in range(8):\n",
    "            if true_label[index] >= 0.5:\n",
    "                count_true = count_true + 1\n",
    "                ground = ground + self.class_names[index] + \"\\n\"\n",
    "                label_check[index] = 1\n",
    "            if predictions_array[index] >= 0.5:\n",
    "                predicted_true = predicted_true + 1\n",
    "                label_check[index] = label_check[index] + 1\n",
    "\n",
    "        all_match = True\n",
    "        for index in range(8):\n",
    "            if label_check[index]==1:\n",
    "                all_match = False\n",
    "\n",
    "        if count_true == predicted_true and all_match:\n",
    "            color = 'green'\n",
    "        else:\n",
    "            color = 'red'\n",
    "\n",
    "        first, second, third, i, j, k = self.calculate_3_largest(predictions_array, 8)\n",
    "        prediction = \"{} {:2.0f}% \\n\".format(self.class_names[i], 100 * first)\n",
    "        if second >= 0.5:\n",
    "            prediction = prediction + \"{} {:2.0f}% \\n\".format(self.class_names[j], 100 * second)\n",
    "        if third >= 0.5:\n",
    "            prediction = prediction + \"{} {:2.0f}% \\n\".format(self.class_names[k], 100 * third)\n",
    "        plt.xlabel(\"Predicted: {} Ground Truth: {}\".format(prediction, ground), color=color)\n",
    "\n",
    "    def plot_accuracy(self, history, new_folder):\n",
    "        # Hide meanwhile for now\n",
    "        plt.plot(history.history['accuracy'], label='accuracy')\n",
    "        plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.savefig(new_folder)\n",
    "        plt.show()\n",
    "\n",
    "    def calculate_3_largest(self, arr, arr_size):\n",
    "        if arr_size < 3:\n",
    "            print(\" Invalid Input \")\n",
    "            return\n",
    "\n",
    "        third = first = second = -sys.maxsize\n",
    "        index_1 = 0\n",
    "        index_2 = 0\n",
    "        index_3 = 0\n",
    "\n",
    "        for i in range(0, arr_size):\n",
    "            if arr[i] > first:\n",
    "                third = second\n",
    "                second = first\n",
    "                first = arr[i]\n",
    "            elif arr[i] > second:\n",
    "                third = second\n",
    "                second = arr[i]\n",
    "            elif arr[i] > third:\n",
    "                third = arr[i]\n",
    "\n",
    "        for i in range(0, arr_size):\n",
    "            if arr[i] == first:\n",
    "                index_1 = i\n",
    "        for i in range(0, arr_size):\n",
    "            if arr[i] == second and i != index_1:\n",
    "                index_2 = i\n",
    "        for i in range(0, arr_size):\n",
    "            if arr[i] == third and i != index_1 and i!= index_2:\n",
    "                index_3 = i\n",
    "        return first, second, third, index_1, index_2, index_3\n",
    "\n",
    "    def plot_value_array(self, i, predictions_array, true_label):\n",
    "        predictions_array, true_label = predictions_array[i], true_label[i]\n",
    "        plt.grid(False)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        bar_plot = plt.bar(range(8), predictions_array, color=\"#777777\")\n",
    "        plt.xticks(range(8), ('N', 'D', 'G', 'C', 'A', 'H', 'M', 'O'))\n",
    "        plt.ylim([0, 1])\n",
    "\n",
    "        for j in range(8):\n",
    "            if true_label[j] >= 0.5:\n",
    "                bar_plot[j].set_color('green')\n",
    "\n",
    "        for j in range(8):\n",
    "            if predictions_array[j] >= 0.5 and true_label[j] < 0.5:\n",
    "                bar_plot[j].set_color('red')\n",
    "\n",
    "        def bar_label(rects):\n",
    "            for rect in rects:\n",
    "                height = rect.get_height()\n",
    "                value = height * 100\n",
    "                if value > 1:\n",
    "                    plt.annotate('{:2.0f}%'.format(value),\n",
    "                                 xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                                 xytext=(0, 3),  # 3 points vertical offset\n",
    "                                 textcoords=\"offset points\",\n",
    "                                 ha='center', va='bottom')\n",
    "\n",
    "        bar_label(bar_plot)\n",
    "\n",
    "    def ensure_test_prediction_exists(self, predictions):\n",
    "        exists = False\n",
    "        for j in range(8):\n",
    "            if predictions[j] >= 0.5:\n",
    "                exists = True\n",
    "        return exists\n",
    "\n",
    "    def plot_output(self, test_predictions_baseline, y_test, x_test_drawing, test_run):\n",
    "        mpl.rcParams[\"font.size\"] = 7\n",
    "        num_rows = 5\n",
    "        num_cols = 5\n",
    "        num_images = num_rows * num_cols\n",
    "        plt.figure(figsize=(2 * 2 * num_cols, 2 * num_rows))\n",
    "        j = 0\n",
    "        i = 0\n",
    "        while j < num_images:\n",
    "            if self.ensure_test_prediction_exists(test_predictions_baseline[i]):\n",
    "                plt.subplot(num_rows, 2 * num_cols, 2 * j + 1)\n",
    "                self.plot_image(i, test_predictions_baseline, y_test, x_test_drawing)\n",
    "                plt.subplot(num_rows, 2 * num_cols, 2 * j + 2)\n",
    "                self.plot_value_array(i, test_predictions_baseline, y_test)\n",
    "                j = j + 1\n",
    "            i = i + 1\n",
    "            if i > 400:\n",
    "                break\n",
    "\n",
    "        plt.subplots_adjust(bottom=0.08, right=0.95, top=0.94, left=0.05, wspace=0.11, hspace=0.56)\n",
    "        plt.savefig(test_run)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_output_single(self, i, test_predictions_baseline, y_test, x_test_drawing):\n",
    "        plt.figure(figsize=(6, 3))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        self.plot_image(i, test_predictions_baseline, y_test, x_test_drawing)\n",
    "        plt.subplot(1, 2, 2)\n",
    "        self.plot_value_array(i, test_predictions_baseline, y_test)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_confusion_matrix(self, y_true, y_pred, classes, normalize=False, title=None, cmap=plt.cm.Blues):\n",
    "        \"\"\"\n",
    "        This function prints and plots the confusion matrix.\n",
    "        Normalization can be applied by setting `normalize=True`.\n",
    "        \"\"\"\n",
    "        if not title:\n",
    "            if normalize:\n",
    "                title = 'Normalized confusion matrix'\n",
    "            else:\n",
    "                title = 'Confusion matrix, without normalization'\n",
    "\n",
    "        # Compute confusion matrix\n",
    "        cm = confusion_matrix(y_true.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "        # Only use the labels that appear in the data\n",
    "        if normalize:\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            print(\"Normalized confusion matrix\")\n",
    "        else:\n",
    "            print('Confusion matrix, without normalization')\n",
    "\n",
    "        print(cm)\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "        ax.figure.colorbar(im, ax=ax)\n",
    "        # We want to show all ticks...\n",
    "        ax.set(xticks=np.arange(cm.shape[1]),\n",
    "               yticks=np.arange(cm.shape[0]),\n",
    "               # ... and label them with the respective list entries\n",
    "               # xticklabels=classes, yticklabels=classes,\n",
    "               title=title,\n",
    "               ylabel='True label',\n",
    "               xlabel='Predicted label')\n",
    "        ax.set_ylim(8.0, -1.0)\n",
    "        # Rotate the tick labels and set their alignment.\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "                 rotation_mode=\"anchor\")\n",
    "\n",
    "        # Loop over data dimensions and create text annotations.\n",
    "        fmt = '.2f' if normalize else 'd'\n",
    "        thresh = cm.max() / 2.\n",
    "        for i in range(cm.shape[0]):\n",
    "            for j in range(cm.shape[1]):\n",
    "                ax.text(j, i, format(cm[i, j], fmt),\n",
    "                        ha=\"center\", va=\"center\",\n",
    "                        color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        fig.tight_layout()\n",
    "        return ax\n",
    "\n",
    "    def print_normalized_confusion_matrix(self, y_test, test_predictions_baseline):\n",
    "        np.set_printoptions(precision=2)\n",
    "\n",
    "        # Plot non-normalized confusion matrix\n",
    "        self.plot_confusion_matrix(y_test, test_predictions_baseline, classes=self.class_names,\n",
    "                                   title='Confusion matrix, without normalization')\n",
    "\n",
    "        # Plot normalized confusion matrix\n",
    "        self.plot_confusion_matrix(y_test, test_predictions_baseline, classes=self.class_names, normalize=True,\n",
    "                                   title='Normalized confusion matrix')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def plot_confusion_matrix_generic(self, labels2, predictions, test_run, p=0.5):\n",
    "        cm = confusion_matrix(labels2.argmax(axis=1), predictions.argmax(axis=1))\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        ax = sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "        ax.set_ylim(8.0, -1.0)\n",
    "        plt.title('Confusion matrix')\n",
    "        plt.ylabel('Actual label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        plt.savefig(test_run)\n",
    "        plt.subplots_adjust(top=0.94, bottom=0.11, left=0.12, right=1.00, hspace=0.20, wspace=0.18)\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2e3d10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "class FinalScore:\n",
    "    def __init__(self, new_folder):\n",
    "        self.new_folder = new_folder\n",
    "\n",
    "\n",
    "    def odir_metrics(self, gt_data, pr_data):\n",
    "        th = 0.5\n",
    "        gt = gt_data.flatten()\n",
    "        pr = pr_data.flatten()\n",
    "        kappa = metrics.cohen_kappa_score(gt, pr > th)\n",
    "        f1 = metrics.f1_score(gt, pr > th, average='micro')\n",
    "        auc = metrics.roc_auc_score(gt, pr)\n",
    "        final_score = (kappa + f1 + auc) / 3.0\n",
    "        return kappa, f1, auc, final_score\n",
    "\n",
    "    def import_data(self, filepath):\n",
    "        with open(filepath, 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            header = next(reader)\n",
    "            pr_data = [[int(row[0])] + list(map(float, row[1:])) for row in reader]\n",
    "        pr_data = np.array(pr_data)\n",
    "        return pr_data\n",
    "\n",
    "    def output(self):\n",
    "        gt_data = self.import_data(os.path.join(self.new_folder, 'Eyeonic_ground_truth.csv')) #\n",
    "        pr_data = self.import_data(os.path.join(self.new_folder, 'Eyeonic_predictions.csv'))\n",
    "        kappa, f1, auc, final_score = self.odir_metrics(gt_data[:, 1:], pr_data[:, 1:])\n",
    "        print(\"Kappa score:\", kappa)\n",
    "        print(\"F-1 score:\", f1)\n",
    "        print(\"AUC value:\", auc)\n",
    "        print(\"Final Score:\", final_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e497e87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "\n",
    "class Prediction:\n",
    "    def __init__(self, prediction, num_images_test, folder = \"\"):\n",
    "        self.prediction = prediction\n",
    "        self.num_images_test = num_images_test\n",
    "        self.folder = folder\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\"Generate a CSV that contains the output of all the classes.\n",
    "        Args:\n",
    "          No arguments are required.\n",
    "        Returns:\n",
    "          File with the output\n",
    "        \"\"\"\n",
    "        # The process here is to generate a CSV file with the content of the data annotations file\n",
    "        # and also the total of labels per eye. This will help us later to process the images\n",
    "        if self.folder != \"\":\n",
    "            folder_to_save = os.path.join(self.folder, 'predictions.csv')\n",
    "        else:\n",
    "            folder_to_save = 'predictions.csv'\n",
    "        with open(folder_to_save, 'w', newline='') as csv_file:\n",
    "            file_writer = csv.writer(csv_file, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "            file_writer.writerow(['ID', 'Normal', 'Diabetes', 'Glaucoma', 'Cataract', 'AMD', 'Hypertension', 'Myopia', 'Others'])\n",
    "            count = 0\n",
    "            for sub in self.prediction:\n",
    "                normal = sub[0]\n",
    "                diabetes = sub[1]\n",
    "                glaucoma = sub[2]\n",
    "                cataract = sub[3]\n",
    "                amd = sub[4]\n",
    "                hypertension = sub[5]\n",
    "                myopia = sub[6]\n",
    "                others = sub[7]\n",
    "                file_writer.writerow([count, normal, diabetes, glaucoma, cataract, amd, hypertension, myopia, others])\n",
    "                count = count + 1\n",
    "\n",
    "    def save_all(self, y_test):\n",
    "        \"\"\"Generate a CSV that contains the output of all the classes.\n",
    "        Args:\n",
    "          No arguments are required.\n",
    "        Returns:\n",
    "          File with the output\n",
    "        \"\"\"\n",
    "        # The process here is to generate a CSV file with the content of the data annotations file\n",
    "        # and also the total of labels per eye. This will help us later to process the images\n",
    "        if self.folder != \"\":\n",
    "            folder_to_save = os.path.join(self.folder, 'Eyeonic_predictions.csv')\n",
    "        else:\n",
    "            folder_to_save = 'Eyeonic_predictions.csv'\n",
    "        with open(folder_to_save, 'w', newline='') as csv_file:\n",
    "            file_writer = csv.writer(csv_file, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "            file_writer.writerow(['ID', 'N', 'D', 'G', 'C', 'A', 'H', 'M', 'O'])\n",
    "            count = 0\n",
    "            for i in range(self.num_images_test):\n",
    "                normal = self.prediction[i][0]\n",
    "                diabetes = self.prediction[i][1]\n",
    "                glaucoma = self.prediction[i][2]\n",
    "                cataract = self.prediction[i][3]\n",
    "                amd = self.prediction[i][4]\n",
    "                hypertension = self.prediction[i][5]\n",
    "                myopia = self.prediction[i][6]\n",
    "                others = self.prediction[i][7]\n",
    "                file_writer.writerow([count, normal, diabetes, glaucoma, cataract, amd, hypertension, myopia, others])\n",
    "                count = count + 1\n",
    "\n",
    "        if self.folder != \"\":\n",
    "            folder_to_save = os.path.join(self.folder, 'Eyeonic_ground_truth.csv')\n",
    "        else:\n",
    "            folder_to_save = 'Eyeonic_ground_truth.csv'\n",
    "        with open(folder_to_save, 'w', newline='') as csv_file:\n",
    "            file_writer = csv.writer(csv_file, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "            file_writer.writerow(['ID', 'N', 'D', 'G', 'C', 'A', 'H', 'M', 'O'])\n",
    "            count = 0\n",
    "            for i in range(self.num_images_test):\n",
    "                normal2 = y_test[i][0]\n",
    "                diabetes2 = y_test[i][1]\n",
    "                glaucoma2 = y_test[i][2]\n",
    "                cataract2 = y_test[i][3]\n",
    "                amd2 = y_test[i][4]\n",
    "                hypertension2 = y_test[i][5]\n",
    "                myopia2 = y_test[i][6]\n",
    "                others2 = y_test[i][7]\n",
    "\n",
    "                file_writer.writerow([count, normal2, diabetes2, glaucoma2, cataract2, amd2, hypertension2, myopia2, others2])\n",
    "                count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aff7fdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_data(image_size, index = 0, challenge = 0):\n",
    "\n",
    "    if index == 0:\n",
    "        x_train = np.load('odir_training' + '_' + str(image_size) + '.npy')\n",
    "        y_train = np.load('odir_training_labels' + '_' + str(image_size) + '.npy')\n",
    "    else:\n",
    "        x_train = np.load('odir_training' + '_' + str(image_size) + '_'  + '.npy')\n",
    "        y_train = np.load('odir_training_labels' + '_' + str(image_size) + '_' + str(index) + '.npy')\n",
    "\n",
    "    if challenge == 0:\n",
    "        x_test = np.load('odir_testing'+'_' + str(image_size)+'.npy')\n",
    "        y_test = np.load('odir_testing_labels'+'_' + str(image_size)+'.npy')\n",
    "    else:\n",
    "        x_test = np.load('odir_testing_challenge'+'_' + str(image_size)+'.npy')\n",
    "        y_test = np.load('odir_testing_labels_challenge'+'_' + str(image_size)+'.npy')\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64194321",
   "metadata": {},
   "source": [
    "# InceptionResNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ca93c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import inception_resnet_v2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.optimizers import legacy\n",
    "import secrets\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "\n",
    "# batch_size = 32\n",
    "batch_size = 16\n",
    "num_classes = 8\n",
    "# epochs = 100\n",
    "epochs = 3\n",
    "patience = 3\n",
    "freeze_layers = 2\n",
    "\n",
    "# class_weight = {0: 1.,\n",
    "#                 1: 1.583802025,\n",
    "#                 2: 8.996805112,\n",
    "#                 3: 10.24,\n",
    "#                 4: 10.05714286,\n",
    "#                 5: 1.,\n",
    "#                 6: 1.,\n",
    "#                 7: 2.505338078}\n",
    "\n",
    "token = secrets.token_hex(16)\n",
    "folder = r'/content/drive/MyDrive/AIMedic/OcularDisease/InceptionResNetV2_basic_outputs'\n",
    "\n",
    "new_folder = os.path.join(folder, token)\n",
    "\n",
    "if not os.path.exists(new_folder):\n",
    "    os.makedirs(new_folder)\n",
    "\n",
    "base_model = inception_resnet_v2.InceptionResNetV2\n",
    "\n",
    "base_model = base_model(weights='imagenet', include_top=False)\n",
    "\n",
    "# Comment this out if you want to train all layers\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = True\n",
    "\n",
    "x = base_model.output\n",
    "#x = Flatten()(x)\n",
    "#x = Dropout(0.5)(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='sigmoid')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "tf.keras.utils.plot_model(model, to_file=os.path.join(new_folder, 'model_inception_resnet_v2.png'), show_shapes=True, show_layer_names=True)\n",
    "\n",
    "defined_metrics = [\n",
    "    tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall'),\n",
    "    tf.keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "\n",
    "sgd = legacy.SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "print('Configuration Start -------------------------')\n",
    "print(sgd.get_config())\n",
    "print('Configuration End -------------------------')\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=defined_metrics)\n",
    "\n",
    "#________________exists above____________________\n",
    "(x_train, y_train), (x_test, y_test) = load_data(224, 1)\n",
    "\n",
    "x_test_drawing = x_test\n",
    "\n",
    "class_names = ['Normal', 'Diabetes', 'Glaucoma', 'Cataract', 'AMD', 'Hypertension', 'Myopia', 'Others']\n",
    "\n",
    "# plot data input\n",
    "plotter = Plotter(class_names)\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca4c9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True, #class_weight= class_weight,\n",
    "                    validation_data=(x_test, y_test), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31879562",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"saving weights\")\n",
    "model.save(os.path.join(new_folder, 'model_weights.h5'))\n",
    "\n",
    "print(\"plotting metrics\")\n",
    "plotter.plot_metrics(history, os.path.join(new_folder, 'plot1.png'), 2)\n",
    "\n",
    "print(\"plotting accuracy\")\n",
    "plotter.plot_accuracy(history, os.path.join(new_folder, 'plot2.png'))\n",
    "\n",
    "print(\"display the content of the model\")\n",
    "baseline_results = model.evaluate(x_test, y_test, verbose=2)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "    print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "# test a prediction\n",
    "test_predictions_baseline = model.predict(x_test)\n",
    "print(\"plotting confusion matrix\")\n",
    "plotter.plot_confusion_matrix_generic(y_test, test_predictions_baseline, os.path.join(new_folder, 'plot3.png'), 0)\n",
    "\n",
    "# save the predictions\n",
    "prediction_writer = Prediction(test_predictions_baseline, 400, new_folder)\n",
    "prediction_writer.save()\n",
    "prediction_writer.save_all(y_test)\n",
    "\n",
    "# show the final score\n",
    "score = FinalScore(new_folder)\n",
    "score.output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f19f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot output results\n",
    "plotter.plot_output(test_predictions_baseline, y_test, x_test_drawing, os.path.join(new_folder, 'plot4.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a86630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851023ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c38888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a310d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#our final model complete "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
