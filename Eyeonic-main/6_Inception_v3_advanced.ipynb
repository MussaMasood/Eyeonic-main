{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e4efd23",
   "metadata": {},
   "source": [
    "# Required Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8666fa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "class Plotter:\n",
    "    def __init__(self, class_names):\n",
    "        self.class_names = class_names\n",
    "\n",
    "    def plot_metrics(self, history, test_run, index):\n",
    "        metrics2 = ['loss', 'auc', 'precision', 'recall']\n",
    "        for n, metric in enumerate(metrics2):\n",
    "            name = metric.replace(\"_\", \" \").capitalize()\n",
    "            plt.subplot(2, 2, n + 1)\n",
    "            plt.plot(history.epoch, history.history[metric], color='green', label='Train')\n",
    "            plt.plot(history.epoch, history.history['val_' + metric], color='green', linestyle=\"--\", label='Val')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel(name)\n",
    "            if metric == 'loss':\n",
    "                plt.ylim([0, plt.ylim()[1]])\n",
    "            elif metric == 'auc':\n",
    "                plt.ylim([0, 1])\n",
    "            else:\n",
    "                plt.ylim([0, 1])\n",
    "\n",
    "            plt.legend()\n",
    "\n",
    "        #fig_manager = plt.get_current_fig_manager()\n",
    "        #fig_manager.full_screen_toggle()\n",
    "        plt.subplots_adjust(top=0.97, bottom=0.09, left=0.10, right=0.96, hspace=0.25, wspace=0.26)\n",
    "        plt.savefig(test_run)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    def plot_input_images(self, x_train, y_train):\n",
    "        plt.figure(figsize=(9, 9))\n",
    "        for i in range(100):\n",
    "            plt.subplot(10, 10, i + 1)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.grid(False)\n",
    "            plt.imshow(x_train[i])\n",
    "            classes = \"\"\n",
    "            for j in range(8):\n",
    "                if y_train[i][j] >= 0.5:\n",
    "                    classes = classes + self.class_names[j] + \"\\n\"\n",
    "            plt.xlabel(classes, fontsize=7, color='black', labelpad=1)\n",
    "\n",
    "        plt.subplots_adjust(bottom=0.04, right=0.95, top=0.94, left=0.06, wspace=0.56, hspace=0.17)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_image(self, i, predictions_array, true_label, img):\n",
    "        predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
    "        plt.grid(False)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "\n",
    "        plt.imshow(img)\n",
    "        label_check = [0,0,0,0,0,0,0,0]\n",
    "        ground = \"\"\n",
    "        count_true = 0\n",
    "        predicted_true = 0\n",
    "\n",
    "        for index in range(8):\n",
    "            if true_label[index] >= 0.5:\n",
    "                count_true = count_true + 1\n",
    "                ground = ground + self.class_names[index] + \"\\n\"\n",
    "                label_check[index] = 1\n",
    "            if predictions_array[index] >= 0.5:\n",
    "                predicted_true = predicted_true + 1\n",
    "                label_check[index] = label_check[index] + 1\n",
    "\n",
    "        all_match = True\n",
    "        for index in range(8):\n",
    "            if label_check[index]==1:\n",
    "                all_match = False\n",
    "\n",
    "        if count_true == predicted_true and all_match:\n",
    "            color = 'green'\n",
    "        else:\n",
    "            color = 'red'\n",
    "\n",
    "        first, second, third, i, j, k = self.calculate_3_largest(predictions_array, 8)\n",
    "        prediction = \"{} {:2.0f}% \\n\".format(self.class_names[i], 100 * first)\n",
    "        if second >= 0.5:\n",
    "            prediction = prediction + \"{} {:2.0f}% \\n\".format(self.class_names[j], 100 * second)\n",
    "        if third >= 0.5:\n",
    "            prediction = prediction + \"{} {:2.0f}% \\n\".format(self.class_names[k], 100 * third)\n",
    "        plt.xlabel(\"Predicted: {} Ground Truth: {}\".format(prediction, ground), color=color)\n",
    "\n",
    "    def plot_accuracy(self, history, new_folder):\n",
    "        # Hide meanwhile for now\n",
    "        plt.plot(history.history['accuracy'], label='accuracy')\n",
    "        plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.savefig(new_folder)\n",
    "        plt.show()\n",
    "\n",
    "    def calculate_3_largest(self, arr, arr_size):\n",
    "        if arr_size < 3:\n",
    "            print(\" Invalid Input \")\n",
    "            return\n",
    "\n",
    "        third = first = second = -sys.maxsize\n",
    "        index_1 = 0\n",
    "        index_2 = 0\n",
    "        index_3 = 0\n",
    "\n",
    "        for i in range(0, arr_size):\n",
    "            if arr[i] > first:\n",
    "                third = second\n",
    "                second = first\n",
    "                first = arr[i]\n",
    "            elif arr[i] > second:\n",
    "                third = second\n",
    "                second = arr[i]\n",
    "            elif arr[i] > third:\n",
    "                third = arr[i]\n",
    "\n",
    "        for i in range(0, arr_size):\n",
    "            if arr[i] == first:\n",
    "                index_1 = i\n",
    "        for i in range(0, arr_size):\n",
    "            if arr[i] == second and i != index_1:\n",
    "                index_2 = i\n",
    "        for i in range(0, arr_size):\n",
    "            if arr[i] == third and i != index_1 and i!= index_2:\n",
    "                index_3 = i\n",
    "        return first, second, third, index_1, index_2, index_3\n",
    "\n",
    "    def plot_value_array(self, i, predictions_array, true_label):\n",
    "        predictions_array, true_label = predictions_array[i], true_label[i]\n",
    "        plt.grid(False)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        bar_plot = plt.bar(range(8), predictions_array, color=\"#777777\")\n",
    "        plt.xticks(range(8), ('N', 'D', 'G', 'C', 'A', 'H', 'M', 'O'))\n",
    "        plt.ylim([0, 1])\n",
    "\n",
    "        for j in range(8):\n",
    "            if true_label[j] >= 0.5:\n",
    "                bar_plot[j].set_color('green')\n",
    "\n",
    "        for j in range(8):\n",
    "            if predictions_array[j] >= 0.5 and true_label[j] < 0.5:\n",
    "                bar_plot[j].set_color('red')\n",
    "\n",
    "        def bar_label(rects):\n",
    "            for rect in rects:\n",
    "                height = rect.get_height()\n",
    "                value = height * 100\n",
    "                if value > 1:\n",
    "                    plt.annotate('{:2.0f}%'.format(value),\n",
    "                                 xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                                 xytext=(0, 3),  # 3 points vertical offset\n",
    "                                 textcoords=\"offset points\",\n",
    "                                 ha='center', va='bottom')\n",
    "\n",
    "        bar_label(bar_plot)\n",
    "\n",
    "    def ensure_test_prediction_exists(self, predictions):\n",
    "        exists = False\n",
    "        for j in range(8):\n",
    "            if predictions[j] >= 0.5:\n",
    "                exists = True\n",
    "        return exists\n",
    "\n",
    "    def plot_output(self, test_predictions_baseline, y_test, x_test_drawing, test_run):\n",
    "        mpl.rcParams[\"font.size\"] = 7\n",
    "        num_rows = 5\n",
    "        num_cols = 5\n",
    "        num_images = num_rows * num_cols\n",
    "        plt.figure(figsize=(2 * 2 * num_cols, 2 * num_rows))\n",
    "        j = 0\n",
    "        i = 0\n",
    "        while j < num_images:\n",
    "            if self.ensure_test_prediction_exists(test_predictions_baseline[i]):\n",
    "                plt.subplot(num_rows, 2 * num_cols, 2 * j + 1)\n",
    "                self.plot_image(i, test_predictions_baseline, y_test, x_test_drawing)\n",
    "                plt.subplot(num_rows, 2 * num_cols, 2 * j + 2)\n",
    "                self.plot_value_array(i, test_predictions_baseline, y_test)\n",
    "                j = j + 1\n",
    "            i = i + 1\n",
    "            if i > 400:\n",
    "                break\n",
    "\n",
    "        plt.subplots_adjust(bottom=0.08, right=0.95, top=0.94, left=0.05, wspace=0.11, hspace=0.56)\n",
    "        plt.savefig(test_run)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_output_single(self, i, test_predictions_baseline, y_test, x_test_drawing):\n",
    "        plt.figure(figsize=(6, 3))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        self.plot_image(i, test_predictions_baseline, y_test, x_test_drawing)\n",
    "        plt.subplot(1, 2, 2)\n",
    "        self.plot_value_array(i, test_predictions_baseline, y_test)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_confusion_matrix(self, y_true, y_pred, classes, normalize=False, title=None, cmap=plt.cm.Blues):\n",
    "        \"\"\"\n",
    "        This function prints and plots the confusion matrix.\n",
    "        Normalization can be applied by setting `normalize=True`.\n",
    "        \"\"\"\n",
    "        if not title:\n",
    "            if normalize:\n",
    "                title = 'Normalized confusion matrix'\n",
    "            else:\n",
    "                title = 'Confusion matrix, without normalization'\n",
    "\n",
    "        # Compute confusion matrix\n",
    "        cm = confusion_matrix(y_true.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "        # Only use the labels that appear in the data\n",
    "        if normalize:\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            print(\"Normalized confusion matrix\")\n",
    "        else:\n",
    "            print('Confusion matrix, without normalization')\n",
    "\n",
    "        print(cm)\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "        ax.figure.colorbar(im, ax=ax)\n",
    "        # We want to show all ticks...\n",
    "        ax.set(xticks=np.arange(cm.shape[1]),\n",
    "               yticks=np.arange(cm.shape[0]),\n",
    "               # ... and label them with the respective list entries\n",
    "               # xticklabels=classes, yticklabels=classes,\n",
    "               title=title,\n",
    "               ylabel='True label',\n",
    "               xlabel='Predicted label')\n",
    "        ax.set_ylim(8.0, -1.0)\n",
    "        # Rotate the tick labels and set their alignment.\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "                 rotation_mode=\"anchor\")\n",
    "\n",
    "        # Loop over data dimensions and create text annotations.\n",
    "        fmt = '.2f' if normalize else 'd'\n",
    "        thresh = cm.max() / 2.\n",
    "        for i in range(cm.shape[0]):\n",
    "            for j in range(cm.shape[1]):\n",
    "                ax.text(j, i, format(cm[i, j], fmt),\n",
    "                        ha=\"center\", va=\"center\",\n",
    "                        color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        fig.tight_layout()\n",
    "        return ax\n",
    "\n",
    "    def print_normalized_confusion_matrix(self, y_test, test_predictions_baseline):\n",
    "        np.set_printoptions(precision=2)\n",
    "\n",
    "        # Plot non-normalized confusion matrix\n",
    "        self.plot_confusion_matrix(y_test, test_predictions_baseline, classes=self.class_names,\n",
    "                                   title='Confusion matrix, without normalization')\n",
    "\n",
    "        # Plot normalized confusion matrix\n",
    "        self.plot_confusion_matrix(y_test, test_predictions_baseline, classes=self.class_names, normalize=True,\n",
    "                                   title='Normalized confusion matrix')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def plot_confusion_matrix_generic(self, labels2, predictions, test_run, p=0.5):\n",
    "        cm = confusion_matrix(labels2.argmax(axis=1), predictions.argmax(axis=1))\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        ax = sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "        ax.set_ylim(8.0, -1.0)\n",
    "        plt.title('Confusion matrix')\n",
    "        plt.ylabel('Actual label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        plt.savefig(test_run)\n",
    "        plt.subplots_adjust(top=0.94, bottom=0.11, left=0.12, right=1.00, hspace=0.20, wspace=0.18)\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233e4b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "class FinalScore:\n",
    "    def __init__(self, new_folder):\n",
    "        self.new_folder = new_folder\n",
    "\n",
    "\n",
    "    def odir_metrics(self, gt_data, pr_data):\n",
    "        th = 0.5\n",
    "        gt = gt_data.flatten()\n",
    "        pr = pr_data.flatten()\n",
    "        kappa = metrics.cohen_kappa_score(gt, pr > th)\n",
    "        f1 = metrics.f1_score(gt, pr > th, average='micro')\n",
    "        auc = metrics.roc_auc_score(gt, pr)\n",
    "        final_score = (kappa + f1 + auc) / 3.0\n",
    "        return kappa, f1, auc, final_score\n",
    "\n",
    "    def import_data(self, filepath):\n",
    "        with open(filepath, 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            header = next(reader)\n",
    "            pr_data = [[int(row[0])] + list(map(float, row[1:])) for row in reader]\n",
    "        pr_data = np.array(pr_data)\n",
    "        return pr_data\n",
    "\n",
    "    def output(self):\n",
    "        gt_data = self.import_data(os.path.join(self.new_folder, 'odir_ground_truth.csv')) #\n",
    "        pr_data = self.import_data(os.path.join(self.new_folder, 'odir_predictions.csv'))\n",
    "        kappa, f1, auc, final_score = self.odir_metrics(gt_data[:, 1:], pr_data[:, 1:])\n",
    "        print(\"Kappa score:\", kappa)\n",
    "        print(\"F-1 score:\", f1)\n",
    "        print(\"AUC value:\", auc)\n",
    "        print(\"Final Score:\", final_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db3303a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "\n",
    "class Prediction:\n",
    "    def __init__(self, prediction, num_images_test, folder = \"\"):\n",
    "        self.prediction = prediction\n",
    "        self.num_images_test = num_images_test\n",
    "        self.folder = folder\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\"Generate a CSV that contains the output of all the classes.\n",
    "        Args:\n",
    "          No arguments are required.\n",
    "        Returns:\n",
    "          File with the output\n",
    "        \"\"\"\n",
    "        # The process here is to generate a CSV file with the content of the data annotations file\n",
    "        # and also the total of labels per eye. This will help us later to process the images\n",
    "        if self.folder != \"\":\n",
    "            folder_to_save = os.path.join(self.folder, 'predictions.csv')\n",
    "        else:\n",
    "            folder_to_save = 'predictions.csv'\n",
    "        with open(folder_to_save, 'w', newline='') as csv_file:\n",
    "            file_writer = csv.writer(csv_file, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "            file_writer.writerow(['ID', 'Normal', 'Diabetes', 'Glaucoma', 'Cataract', 'AMD', 'Hypertension', 'Myopia', 'Others'])\n",
    "            count = 0\n",
    "            for sub in self.prediction:\n",
    "                normal = sub[0]\n",
    "                diabetes = sub[1]\n",
    "                glaucoma = sub[2]\n",
    "                cataract = sub[3]\n",
    "                amd = sub[4]\n",
    "                hypertension = sub[5]\n",
    "                myopia = sub[6]\n",
    "                others = sub[7]\n",
    "                file_writer.writerow([count, normal, diabetes, glaucoma, cataract, amd, hypertension, myopia, others])\n",
    "                count = count + 1\n",
    "\n",
    "    def save_all(self, y_test):\n",
    "        \"\"\"Generate a CSV that contains the output of all the classes.\n",
    "        Args:\n",
    "          No arguments are required.\n",
    "        Returns:\n",
    "          File with the output\n",
    "        \"\"\"\n",
    "        # The process here is to generate a CSV file with the content of the data annotations file\n",
    "        # and also the total of labels per eye. This will help us later to process the images\n",
    "        if self.folder != \"\":\n",
    "            folder_to_save = os.path.join(self.folder, 'odir_predictions.csv')\n",
    "        else:\n",
    "            folder_to_save = 'odir_predictions.csv'\n",
    "        with open(folder_to_save, 'w', newline='') as csv_file:\n",
    "            file_writer = csv.writer(csv_file, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "            file_writer.writerow(['ID', 'N', 'D', 'G', 'C', 'A', 'H', 'M', 'O'])\n",
    "            count = 0\n",
    "            for i in range(self.num_images_test):\n",
    "                normal = self.prediction[i][0]\n",
    "                diabetes = self.prediction[i][1]\n",
    "                glaucoma = self.prediction[i][2]\n",
    "                cataract = self.prediction[i][3]\n",
    "                amd = self.prediction[i][4]\n",
    "                hypertension = self.prediction[i][5]\n",
    "                myopia = self.prediction[i][6]\n",
    "                others = self.prediction[i][7]\n",
    "                file_writer.writerow([count, normal, diabetes, glaucoma, cataract, amd, hypertension, myopia, others])\n",
    "                count = count + 1\n",
    "\n",
    "        if self.folder != \"\":\n",
    "            folder_to_save = os.path.join(self.folder, 'odir_ground_truth.csv')\n",
    "        else:\n",
    "            folder_to_save = 'odir_ground_truth.csv'\n",
    "        with open(folder_to_save, 'w', newline='') as csv_file:\n",
    "            file_writer = csv.writer(csv_file, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "            file_writer.writerow(['ID', 'N', 'D', 'G', 'C', 'A', 'H', 'M', 'O'])\n",
    "            count = 0\n",
    "            for i in range(self.num_images_test):\n",
    "                normal2 = y_test[i][0]\n",
    "                diabetes2 = y_test[i][1]\n",
    "                glaucoma2 = y_test[i][2]\n",
    "                cataract2 = y_test[i][3]\n",
    "                amd2 = y_test[i][4]\n",
    "                hypertension2 = y_test[i][5]\n",
    "                myopia2 = y_test[i][6]\n",
    "                others2 = y_test[i][7]\n",
    "\n",
    "                file_writer.writerow([count, normal2, diabetes2, glaucoma2, cataract2, amd2, hypertension2, myopia2, others2])\n",
    "                count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0836e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_data(image_size, index = 0, challenge = 0):\n",
    "    \"\"\"Loads the ODIR dataset.\n",
    "    Returns:\n",
    "      Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n",
    "    \"\"\"\n",
    "\n",
    "    if index == 0:\n",
    "        x_train = np.load('odir_training' + '_' + str(image_size) + '.npy')\n",
    "        y_train = np.load('odir_training_labels' + '_' + str(image_size) + '.npy')\n",
    "    else:\n",
    "        x_train = np.load('odir_training' + '_' + str(image_size) + '_'  + '.npy')\n",
    "        y_train = np.load('odir_training_labels' + '_' + str(image_size) + '_' + str(index) + '.npy')\n",
    "\n",
    "    if challenge == 0:\n",
    "        x_test = np.load('odir_testing'+'_' + str(image_size)+'.npy')\n",
    "        y_test = np.load('odir_testing_labels'+'_' + str(image_size)+'.npy')\n",
    "    else:\n",
    "        x_test = np.load('odir_testing_challenge'+'_' + str(image_size)+'.npy')\n",
    "        y_test = np.load('odir_testing_labels_challenge'+'_' + str(image_size)+'.npy')\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66d4730",
   "metadata": {},
   "source": [
    "## Inception_advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7024ac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections.abc import Sequence\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications import resnet50, inception_v3, vgg16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n",
    "import numpy as np\n",
    "import secrets\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# batch_size = 32\n",
    "batch_size = 16\n",
    "num_classes = 8\n",
    "# epochs = 30\n",
    "epochs = 1\n",
    "\n",
    "\n",
    "class Generator(Sequence):\n",
    "    # Class is a dataset wrapper for better training performance\n",
    "    def __init__(self, x_set, y_set, batch_size=256):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.indices = np.arange(self.x.shape[0])\n",
    "\n",
    "    def __len__(self):\n",
    "        return np.math.ceil(self.x.shape[0] / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inds = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_x = self.x[inds]\n",
    "        batch_y = self.y[inds]\n",
    "        return batch_x, batch_y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.indices)\n",
    "\n",
    "def generator(train_a, labels_a, train_b, labels_b):\n",
    "    while True:\n",
    "        for i in range(len(train_a)):\n",
    "            yield train_a[i].reshape(1, 224, 224, 3), labels_a[i].reshape(1, 8)\n",
    "        for i in range(len(train_b)):\n",
    "            yield train_b[i].reshape(1, 224, 224, 3), labels_b[i].reshape(1, 8)\n",
    "\n",
    "def generator_validation(test, labels):\n",
    "    while True:\n",
    "        for i in range(len(test)):\n",
    "            yield test[i].reshape(1, 224, 224, 3), labels[i].reshape(1, 8)\n",
    "\n",
    "token = secrets.token_hex(16)\n",
    "folder = r'C:\\Users\\mussa\\Desktop\\fyp-1\\preprocessing mussa\\Inception_enhanced_outputs\\Inception_enhanced_outputs'\n",
    "\n",
    "newfolder = os.path.join(folder, token)\n",
    "if not os.path.exists(newfolder):\n",
    "    os.makedirs(newfolder)\n",
    "\n",
    "base_model = inception_v3.InceptionV3\n",
    "\n",
    "base_model = base_model(weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='sigmoid')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "# model.summary()\n",
    "\n",
    "tf.keras.utils.plot_model(model, to_file=os.path.join(newfolder, 'model_inception_v3.png'), show_shapes=True, show_layer_names=True)\n",
    "\n",
    "\n",
    "#for layer in base_model.layers:\n",
    "#    layer.trainable = False\n",
    "\n",
    "defined_metrics = [\n",
    "    tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall'),\n",
    "    tf.keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(learning_rate=0.001),\n",
    "              metrics=defined_metrics)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_data(224, 1)\n",
    "(x_train2, y_train2), (x_test, y_test) = load_data(224, 2)\n",
    "\n",
    "x_test_drawing = x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6b33b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Normal', 'Diabetes', 'Glaucoma', 'Cataract', 'AMD', 'Hypertension', 'Myopia', 'Others']\n",
    "\n",
    "# plot data input\n",
    "plotter = Plotter(class_names)\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, mode='min', verbose=1)\n",
    "\n",
    "# class_weight = {0: 1.,\n",
    "#                     1: 1.583802025,\n",
    "#                     2: 8.996805112,\n",
    "#                     3: 10.24,\n",
    "#                     4: 10.05714286,\n",
    "#                     5: 14.66666667,\n",
    "#                     6: 10.7480916,\n",
    "#                     7: 2.505338078} , class_weight=class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8423dad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "          epochs=1,\n",
    "          batch_size=batch_size,\n",
    "          shuffle=True,\n",
    "          validation_data=(x_test, y_test), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628697bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"saving\")\n",
    "model.save(os.path.join(newfolder, 'model_weights.h5'))\n",
    "\n",
    "print(\"plotting\")\n",
    "plotter.plot_metrics(history, os.path.join(newfolder, 'plot1.png'), 2)\n",
    "\n",
    "# Hide meanwhile for now\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig(os.path.join(newfolder, 'plot2.png'))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# display the content of the model\n",
    "baseline_results = model.evaluate(x_test, y_test, verbose=2)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "    print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "# test a prediction\n",
    "test_predictions_baseline = model.predict(x_test)\n",
    "plotter.plot_confusion_matrix_generic(y_test, test_predictions_baseline, os.path.join(newfolder, 'plot3.png'), 0)\n",
    "\n",
    "# save the predictions\n",
    "prediction_writer = Prediction(test_predictions_baseline, 400, newfolder)\n",
    "prediction_writer.save()\n",
    "prediction_writer.save_all(y_test)\n",
    "\n",
    "# show the final score\n",
    "score = FinalScore(newfolder)\n",
    "score.output()\n",
    "\n",
    "# plot output results\n",
    "plotter.plot_output(test_predictions_baseline, y_test, x_test_drawing, os.path.join(newfolder, 'plot4.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8762a385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all code for inception_advanced "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f728d2d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
